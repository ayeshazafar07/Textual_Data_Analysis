{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54e4c9dc-db01-4a9e-ba5a-2f717ecdc691",
   "metadata": {},
   "source": [
    "# Textual Data Analysis - Exercise 1\n",
    "## Name: Ayesha Zafar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e173eed-2af5-4420-b31a-a83458550113",
   "metadata": {},
   "source": [
    "# Part 1: loading a dataset from the HF hub\n",
    "\n",
    "Using the load_dataset function of the datasets library, load each of the following datasets in turn:\n",
    "\n",
    "stanfordnlp/imdb\n",
    "\n",
    "eriktks/conll2003\n",
    "\n",
    "openai/gsm8k\n",
    "\n",
    "For each of the datasets, report the following information:\n",
    "\n",
    "1. What NLP task is the dataset intended for (e.g. syntactic analysis, toxicity detection, etc.)? (You may need to refer to the documentation of the dataset for this.)\n",
    "\n",
    "2. What parts is the dataset split into (e.g. train, test) and how many examples does each contain?\n",
    "\n",
    "3. What features (e.g. text, label) does the dataset have? (Try to understand how these relate to the NLP task the dataset is intended for.)\n",
    "\n",
    "4. What is the first item in the training set of the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827ff442-e00a-4a63-b95b-c30163f42c94",
   "metadata": {},
   "source": [
    "### 1. What NLP task is the dataset intended for (e.g. syntactic analysis, toxicity detection, etc.)? \n",
    "\n",
    "#### stanfordnlp/imdb\n",
    "\n",
    "NLP Task: Sentiment Analysis (The dataset is designed to classify movie reviews as positive (1) or negative (0))\n",
    "\n",
    "#### eriktks/conll2003\n",
    "\n",
    "NLP Task: Named Entity Recognition (NER), Part-of-Speech (POS) tagging, and Syntactic Chunking (This dataset is used for identifying named entities in text (e.g., persons, locations, organizations) and includes POS tags and syntactic chunks)\n",
    "\n",
    "#### openai/gsm8k\n",
    "\n",
    "NLP Task: Math Word Problem Solving (This dataset provides math problems and solutions for training models on mathematical reasoning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a31dab10-3124-42c7-a6d7-3044f01cdaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Dataset: stanfordnlp/imdb\n",
      "  Split: train, Examples: 25000\n",
      "\n",
      "  Split: test, Examples: 25000\n",
      "\n",
      "  Split: unsupervised, Examples: 50000\n",
      "\n",
      "  Features: {'text': Value(dtype='string', id=None), 'label': ClassLabel(names=['neg', 'pos'], id=None)}\n",
      "\n",
      "  First item in training set: {'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.', 'label': 0}\n",
      "\n",
      "=> Dataset: eriktks/conll2003\n",
      "  Split: train, Examples: 14041\n",
      "\n",
      "  Split: validation, Examples: 3250\n",
      "\n",
      "  Split: test, Examples: 3453\n",
      "\n",
      "  Features: {'id': Value(dtype='string', id=None), 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'pos_tags': Sequence(feature=ClassLabel(names=['\"', \"''\", '#', '$', '(', ')', ',', '.', ':', '``', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'NN|SYM', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB'], id=None), length=-1, id=None), 'chunk_tags': Sequence(feature=ClassLabel(names=['O', 'B-ADJP', 'I-ADJP', 'B-ADVP', 'I-ADVP', 'B-CONJP', 'I-CONJP', 'B-INTJ', 'I-INTJ', 'B-LST', 'I-LST', 'B-NP', 'I-NP', 'B-PP', 'I-PP', 'B-PRT', 'I-PRT', 'B-SBAR', 'I-SBAR', 'B-UCP', 'I-UCP', 'B-VP', 'I-VP'], id=None), length=-1, id=None), 'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)}\n",
      "\n",
      "  First item in training set: {'id': '0', 'tokens': ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7], 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0], 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}\n",
      "\n",
      "=> Dataset: openai/gsm8k\n",
      "  Split: train, Examples: 7473\n",
      "\n",
      "  Split: test, Examples: 1319\n",
      "\n",
      "  Features: {'question': Value(dtype='string', id=None), 'answer': Value(dtype='string', id=None)}\n",
      "\n",
      "  First item in training set: {'question': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?', 'answer': 'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Dataset list with optional configurations\n",
    "datasets_list = [\n",
    "    {\"name\": \"stanfordnlp/imdb\", \"config\": None},\n",
    "    {\"name\": \"eriktks/conll2003\", \"config\": None},\n",
    "    {\"name\": \"openai/gsm8k\", \"config\": \"main\"}\n",
    "]\n",
    "\n",
    "# Looping over each dataset \n",
    "for dataset_info in datasets_list:\n",
    "    dataset_name = dataset_info[\"name\"]\n",
    "    config = dataset_info[\"config\"]\n",
    "    print(f\"=> Dataset: {dataset_name}\")\n",
    "    try:\n",
    "        if config:\n",
    "            dataset = load_dataset(dataset_name, config, trust_remote_code=True)\n",
    "        else:\n",
    "            dataset = load_dataset(dataset_name, trust_remote_code=True)\n",
    "        # 2. What parts is the dataset split into (e.g. train, test) and how many examples does each contain?\n",
    "        for split, data in dataset.items():\n",
    "            print(f\"  Split: {split}, Examples: {len(data)}\\n\")\n",
    "        # 3. What features (e.g. text, label) does the dataset have? \n",
    "        print(f\"  Features: {dataset[list(dataset.keys())[0]].features}\\n\")\n",
    "        # 4. What is the first item in the training set of the dataset?\n",
    "        if \"train\" in dataset:\n",
    "            print(f\"  First item in training set: {dataset['train'][0]}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error loading dataset: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda580a3-54c4-4632-9a30-75467b1cd288",
   "metadata": {},
   "source": [
    "# Part 2: creating a dataset from your own data\n",
    "\n",
    "You can find data collected from the Yle news RSS feed here: http://dl.turkunlp.org/TKO_8964_2023/\n",
    "\n",
    "Download either the Finnish or English data (news-fi-2021.jsonl or news-en-2021.jsonl) using wget and create a dataset from the JSONL data (see \n",
    "https://huggingface.co/docs/datasets/loading#json). Answer the following questions:\n",
    "\n",
    "1. What NLP tasks could the dataset be used for?\n",
    "\n",
    "2. What features does the dataset have?\n",
    "\n",
    "3. How many space-separated words do the texts of the dataset contain in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4fd2ec5-2883-42c0-8ce7-7c860cab10cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully and saved as news-en-2021.jsonl\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Downloading dataset using URL\n",
    "url = \"http://dl.turkunlp.org/TKO_8964_2023/news-en-2021.jsonl\"\n",
    "output_file = \"news-en-2021.jsonl\"\n",
    "\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"File downloaded successfully and saved as {output_file}\")\n",
    "else:\n",
    "    print(f\"Failed to download file. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a0273ff-04c2-4049-881b-a4ebc67e78bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['summary', 'tags', 'text', 'timestamp', 'title', 'url'],\n",
      "        num_rows: 1059\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Loading JSONL file as a dataset\n",
    "dataset = load_dataset(\"json\", data_files=\"news-en-2021.jsonl\")\n",
    "\n",
    "# Displaying dataset info\n",
    "print(\"Dataset loaded successfully:\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dd2898-cbb4-43d0-8e90-344a6032c18f",
   "metadata": {},
   "source": [
    "## 1. What NLP tasks could the dataset be used for?\n",
    "\n",
    "Here are some possible NLP tasks:\n",
    "\n",
    "Text classification: Categorizing articles based on topics.\n",
    "\n",
    "Named entity recognition (NER): Identifying entities such as people, locations, and organizations in the text.\n",
    "\n",
    "Summarization: Generating summaries for each news article.\n",
    "\n",
    "Sentiment analysis: Determining the sentiment or tone of the news articles.\n",
    "\n",
    "Language modeling: Training models to predict text sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b141c88-e534-41f2-91b3-dcdf7e9e17aa",
   "metadata": {},
   "source": [
    "## 2. What features does the dataset have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ff86271-27c3-4588-9c4e-9058d01a7e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features of the dataset:\n",
      "{'summary': Value(dtype='string', id=None), 'tags': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'text': Value(dtype='string', id=None), 'timestamp': Value(dtype='timestamp[s]', id=None), 'title': Value(dtype='string', id=None), 'url': Value(dtype='string', id=None)}\n",
      "\n",
      "First item in the dataset:\n",
      "{'summary': 'The decisions follow a meeting of government ministers at the House of the Estates on Thursday afternoon.', 'tags': ['Kotimaan uutiset'], 'text': 'Finland\\'s government is pushing ahead with plans to introduce a Covid pass, following a meeting of ministers at the House of the Estates in Helsinki on Thursday afternoon. \\n \"There are still many open questions that need to be answered. At this point, it is impossible to promise that the pass will come or when it will come,\" Prime Minister  Sanna Marin  (SDP) told the media following the conclusion of the meeting. \\n \"The government has given the green light to the Covid pass and preparations will continue,\" Marin added. \\n Minister of Economic Affairs  Mika Lintilä  (Cen) told reporters immediately after the meeting that there was broad agreement between the coalition parties over the need for the certificate. \\n \"It [the pass] is an important tool so that we will not need restrictions any more,\" Lintilä said. \\n The government also decided at Thursday afternoon\\'s meeting to offer coronavirus vaccines to all 12- to 15-year-olds, starting as early as next week. \\n \"Fortunately, we have received an extra batch of approximately 200,000 doses of vaccine in Finland, from which these vaccinations [for 12- to 15-year-olds] can be started without interfering with other vaccination programmes,\" Marin told Yle\\'s A-studio on Wednesday evening. \\n Restrictions for bars, restaurants in spreading regions \\n Furthermore, the government will reintroduce restrictions on the opening hours and operations of bars and restaurants due to the deteriorating coronavirus situation in regions considered to be in the spreading — or most serious — phase of the epidemic. \\n This means that bars and restaurants in the regions of Southwest Finland, Pirkanmaa and Kymenlaakso, as well as the Helsinki metropolitan area, will have to adapt to new regulations that are due to take effect from Sunday. \\n The measures include the opening hours of bars being limited to between 7am and 10pm, while restaurants can stay open one hour later. A ban on karaoke and dancing indoors has also been reintroduced. \\n There will be no changes to the opening hours of bars or restaurants in regions considered to be in the acceleration phase of the pandemic. \\n Changes to external border traffic \\n The government has also decided to make changes to the restrictions on Finland\\'s external border traffic, according to the Ministry of the Interior. External border traffic refers to traffic between Finland and countries not belonging to the Schengen area. \\n The regulations currently in effect will be amended, beginning from 9 August, so that entry restrictions are removed for Ukrainian residents traveling to Finland from Ukraine. \\n Restrictions on entry will be restored for residents of Azerbaijan, South Korea, Japan, Moldova, Serbia and Singapore travelling from these countries to Finland. \\n If a person arriving from the above-mentioned countries has not received a full series of vaccinations, the permitted entry criteria are a resident returning to Finland or other EU or Schengen countries, transit of regular scheduled flight traffic at the airport, or other essential reasons. \\n A person can travel to Finland from any country by presenting an acceptable certificate of the full vaccination series. \\n These new regulations aside, the restrictions that entered into force on 19 July still apply. \\n The latest restrictions are in effect until 22 August. \\n Protesters demand \"same rules for all\" \\n A small but vocal group of protestors, representing cultural sector workers, gathered near the House of the Estates while the government meeting was ongoing to demonstrate against coronavirus restrictions, demanding a fairer distribution of measures. \\n Restrictions have hit especially hard on the cultural and event industry, with many workers in the sector unable to work for the past year and a half. At the same time, the protestors pointed out, shopping malls have been allowed to operate as normal. \\n \"Same rules for all,\" the protesters chanted.', 'timestamp': datetime.datetime(2021, 8, 5, 14, 58, 29), 'title': 'Government opens vaccinations for 12-15-year-olds, gives green light to Covid pass', 'url': 'https://yle.fi/uutiset/12048911'}\n"
     ]
    }
   ],
   "source": [
    "# Displaying features\n",
    "print(\"Features of the dataset:\")\n",
    "print(dataset['train'].features)\n",
    "\n",
    "# First item\n",
    "print(\"\\nFirst item in the dataset:\")\n",
    "print(dataset['train'][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db45d614-f0e5-41d0-8f26-fb07ee23e18a",
   "metadata": {},
   "source": [
    "## 3. Total Number of Space-Separated Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a30e2656-5765-4cd2-a318-5101816868dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in the dataset: 475975\n"
     ]
    }
   ],
   "source": [
    "def count_words(batch):\n",
    "    # Returning list of word counts for each entry in batch\n",
    "    return {\"word_count\": [len(text.split()) for text in batch[\"text\"]]}\n",
    "\n",
    "# Applying function to entire dataset\n",
    "word_count_result = dataset['train'].map(count_words, batched=True, batch_size=1000)\n",
    "# Calculating total word count \n",
    "total_words = sum(word_count_result[\"word_count\"])\n",
    "# Displaying total word count\n",
    "print(f\"Total number of words in the dataset: {total_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7c57bf-3829-4944-8386-0c8458aed767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
