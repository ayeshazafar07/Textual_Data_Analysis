{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8febe8ff-e2d7-435d-908e-feb8b61ab4fd",
      "metadata": {
        "id": "8febe8ff-e2d7-435d-908e-feb8b61ab4fd"
      },
      "source": [
        "# **Textual Data Analysis - Exercise - 5**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## **Name: Ayesha Zafar**\n",
        "## **Date: 04/02/2025**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### NER inference using a sequence labeling model\n",
        "\n",
        "In this exercise, your task is to extract named entities from the Finnish/English news data collection using fine-tuned sequence labeling model, investigate its predictions, and calculate simple NE statistics.\n",
        "\n",
        "The Finnish/English news data collection is available here: http://dl.turkunlp.org/TKO_8964_2023/news-*.jsonl.\n",
        "\n",
        "If you do the exercise using Finnish data, the suggested fine-tuned model is https://huggingface.co/Kansallisarkisto/finbert-ner. For English, there are many options, but e.g. https://huggingface.co/dslim/bert-base-NER is a reasonable choice.\n",
        "\n",
        "The specific tasks are:\n",
        "\n",
        "1) Read the model page to figure out which datasets were used to train the model, and which entities the model includes.\n",
        "\n",
        "2) Run inference on the news data, and verify whether the model produces invalid label sequences (hint: it does if you run on some amount of data). Here you do not need to take into account subwords to tokens -mapping, but you can directly check the label sequence of subwords (raw predictions). Print statistics for the most common invalid transitions. Hint: If you run the inference using pipeline, it may hide some of the predictions from you. Set the pipeline parameters so that you get access to raw predictions.\n",
        "\n",
        "3) Read about the ´aggregation_strategy´ parameter for token classification pipelines (sometimes source code is the best place to get information...). Based on your reading, select a suitable parameter (or in case you run the inference without using pipelines, write a simple function to implement some simple aggregation strategy), run the inference, and collect predicted named entities. What is the most common entity type in your data and what are the most common entities?\n",
        "\n",
        "It's totally fine to downsample the data, e.g. 50 documents is more than enough and can be easily done on CPU. With GPU runtime, one can run substantial amount of data.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9a70f44-25b7-4568-9b95-359e5024c6ea",
      "metadata": {
        "id": "f9a70f44-25b7-4568-9b95-359e5024c6ea"
      },
      "source": [
        "Step 1. Installing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "605813f7-ac47-4f11-9f95-b5d70d6fbe4d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "605813f7-ac47-4f11-9f95-b5d70d6fbe4d",
        "outputId": "5c3c4524-4634-405c-e7b7-f78e9bcb70b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonlines) (25.1.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets jsonlines"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2. Importing necessary libraries"
      ],
      "metadata": {
        "id": "ZjYZE-60N-az"
      },
      "id": "ZjYZE-60N-az"
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import jsonlines\n",
        "import requests\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "QNyFOjF5N7Xo"
      },
      "id": "QNyFOjF5N7Xo",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3. Fetching the English news dataset"
      ],
      "metadata": {
        "id": "1W8OfEo2ORfy"
      },
      "id": "1W8OfEo2ORfy"
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"http://dl.turkunlp.org/TKO_8964_2023/news-en-2021.jsonl\"\n",
        "response = requests.get(url)\n",
        "data = response.text.splitlines()"
      ],
      "metadata": {
        "id": "0Yj51_aDOKdr"
      },
      "id": "0Yj51_aDOKdr",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4. Parsing json lines with check for malformed lines and printing the first document"
      ],
      "metadata": {
        "id": "iGY3AFfcWzWS"
      },
      "id": "iGY3AFfcWzWS"
    },
    {
      "cell_type": "code",
      "source": [
        "documents = []\n",
        "for line in data:\n",
        "    obj = json.loads(line)\n",
        "    documents.append(obj[\"text\"])\n",
        "\n",
        "documents = documents[:50]\n",
        "\n",
        "print(f\"Total documents: {len(documents)}\")\n",
        "print(\"First document:\")\n",
        "print(documents[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vdRIPByWyo0",
        "outputId": "c229115c-e82d-4c3f-f7e7-1d1c3d217069"
      },
      "id": "8vdRIPByWyo0",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total documents: 50\n",
            "First document:\n",
            "Finland's government is pushing ahead with plans to introduce a Covid pass, following a meeting of ministers at the House of the Estates in Helsinki on Thursday afternoon. \n",
            " \"There are still many open questions that need to be answered. At this point, it is impossible to promise that the pass will come or when it will come,\" Prime Minister  Sanna Marin  (SDP) told the media following the conclusion of the meeting. \n",
            " \"The government has given the green light to the Covid pass and preparations will continue,\" Marin added. \n",
            " Minister of Economic Affairs  Mika Lintilä  (Cen) told reporters immediately after the meeting that there was broad agreement between the coalition parties over the need for the certificate. \n",
            " \"It [the pass] is an important tool so that we will not need restrictions any more,\" Lintilä said. \n",
            " The government also decided at Thursday afternoon's meeting to offer coronavirus vaccines to all 12- to 15-year-olds, starting as early as next week. \n",
            " \"Fortunately, we have received an extra batch of approximately 200,000 doses of vaccine in Finland, from which these vaccinations [for 12- to 15-year-olds] can be started without interfering with other vaccination programmes,\" Marin told Yle's A-studio on Wednesday evening. \n",
            " Restrictions for bars, restaurants in spreading regions \n",
            " Furthermore, the government will reintroduce restrictions on the opening hours and operations of bars and restaurants due to the deteriorating coronavirus situation in regions considered to be in the spreading — or most serious — phase of the epidemic. \n",
            " This means that bars and restaurants in the regions of Southwest Finland, Pirkanmaa and Kymenlaakso, as well as the Helsinki metropolitan area, will have to adapt to new regulations that are due to take effect from Sunday. \n",
            " The measures include the opening hours of bars being limited to between 7am and 10pm, while restaurants can stay open one hour later. A ban on karaoke and dancing indoors has also been reintroduced. \n",
            " There will be no changes to the opening hours of bars or restaurants in regions considered to be in the acceleration phase of the pandemic. \n",
            " Changes to external border traffic \n",
            " The government has also decided to make changes to the restrictions on Finland's external border traffic, according to the Ministry of the Interior. External border traffic refers to traffic between Finland and countries not belonging to the Schengen area. \n",
            " The regulations currently in effect will be amended, beginning from 9 August, so that entry restrictions are removed for Ukrainian residents traveling to Finland from Ukraine. \n",
            " Restrictions on entry will be restored for residents of Azerbaijan, South Korea, Japan, Moldova, Serbia and Singapore travelling from these countries to Finland. \n",
            " If a person arriving from the above-mentioned countries has not received a full series of vaccinations, the permitted entry criteria are a resident returning to Finland or other EU or Schengen countries, transit of regular scheduled flight traffic at the airport, or other essential reasons. \n",
            " A person can travel to Finland from any country by presenting an acceptable certificate of the full vaccination series. \n",
            " These new regulations aside, the restrictions that entered into force on 19 July still apply. \n",
            " The latest restrictions are in effect until 22 August. \n",
            " Protesters demand \"same rules for all\" \n",
            " A small but vocal group of protestors, representing cultural sector workers, gathered near the House of the Estates while the government meeting was ongoing to demonstrate against coronavirus restrictions, demanding a fairer distribution of measures. \n",
            " Restrictions have hit especially hard on the cultural and event industry, with many workers in the sector unable to work for the past year and a half. At the same time, the protestors pointed out, shopping malls have been allowed to operate as normal. \n",
            " \"Same rules for all,\" the protesters chanted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5. Loading NER pipeline with aggregation disabled to get raw predictions"
      ],
      "metadata": {
        "id": "Qj7fbohcOoMl"
      },
      "id": "Qj7fbohcOoMl"
    },
    {
      "cell_type": "code",
      "source": [
        "ner_pipeline = pipeline(\n",
        "    \"token-classification\",\n",
        "    model=\"dslim/bert-base-NER\",\n",
        "    aggregation_strategy=\"none\",\n",
        ")\n",
        "\n",
        "raw_predictions = ner_pipeline(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8rseF05Ot_G",
        "outputId": "7f130e02-62b3-40bf-ff26-4df950bbe4cf"
      },
      "id": "h8rseF05Ot_G",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6. Checking for invalid label sequences and printing most common invalid transitions"
      ],
      "metadata": {
        "id": "bBTgs3MRX02j"
      },
      "id": "bBTgs3MRX02j"
    },
    {
      "cell_type": "code",
      "source": [
        "invalid_transitions = []\n",
        "\n",
        "for doc_preds in raw_predictions:\n",
        "    labels = [pred[\"entity\"] for pred in doc_preds]\n",
        "    for i in range(1, len(labels)):\n",
        "        prev_label, curr_label = labels[i - 1], labels[i]\n",
        "\n",
        "        if prev_label == \"O\" and curr_label.startswith(\"I-\"):\n",
        "            invalid_transitions.append((prev_label, curr_label))\n",
        "        elif prev_label.startswith(\"B-\") and curr_label.startswith(\"I-\"):\n",
        "            prev_entity = prev_label.split(\"-\")[1]\n",
        "            curr_entity = curr_label.split(\"-\")[1]\n",
        "            if prev_entity != curr_entity:\n",
        "                invalid_transitions.append((prev_label, curr_label))\n",
        "\n",
        "transition_counter = Counter(invalid_transitions)\n",
        "print(\"Most common invalid transitions:\")\n",
        "for transition, count in transition_counter.most_common():\n",
        "    print(f\"{transition}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4cku4DmXxRC",
        "outputId": "4d7609ea-21be-4d50-a496-acdb36353afb"
      },
      "id": "m4cku4DmXxRC",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most common invalid transitions:\n",
            "('B-MISC', 'I-ORG'): 6\n",
            "('B-PER', 'I-ORG'): 4\n",
            "('B-ORG', 'I-LOC'): 2\n",
            "('B-LOC', 'I-ORG'): 1\n",
            "('B-MISC', 'I-LOC'): 1\n",
            "('B-ORG', 'I-PER'): 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7. Reloading pipeline with aggregation strategy as 'simple'"
      ],
      "metadata": {
        "id": "U5o8tqvIYTHM"
      },
      "id": "U5o8tqvIYTHM"
    },
    {
      "cell_type": "code",
      "source": [
        "ner_pipeline = pipeline(\n",
        "    \"token-classification\",\n",
        "    model=\"dslim/bert-base-NER\",\n",
        "    aggregation_strategy=\"simple\",\n",
        ")\n",
        "\n",
        "aggregated_predictions = ner_pipeline(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6HUfB7eOwh6",
        "outputId": "71d33606-4a84-4d77-d2cb-09295fbbfa97"
      },
      "id": "x6HUfB7eOwh6",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8. Collecting predicted named entities and printing most frequent types and entities"
      ],
      "metadata": {
        "id": "K68NkI3rYkK_"
      },
      "id": "K68NkI3rYkK_"
    },
    {
      "cell_type": "code",
      "source": [
        "entities = []\n",
        "for doc_preds in aggregated_predictions:\n",
        "    for pred in doc_preds:\n",
        "        entities.append((pred[\"entity_group\"], pred[\"word\"]))\n",
        "\n",
        "entity_counter = Counter([entity[0] for entity in entities])\n",
        "print(\"Most common entity types:\")\n",
        "for entity_type, count in entity_counter.most_common():\n",
        "    print(f\"{entity_type}: {count}\")\n",
        "\n",
        "entity_word_counter = Counter([entity[1] for entity in entities])\n",
        "print(\"\\nMost common entities:\")\n",
        "for entity_word, count in entity_word_counter.most_common(10):\n",
        "    print(f\"{entity_word}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejnJbD--Ykgx",
        "outputId": "a8650b8c-c3b2-4f18-8a0e-e048824faff1"
      },
      "id": "ejnJbD--Ykgx",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most common entity types:\n",
            "ORG: 358\n",
            "PER: 324\n",
            "LOC: 291\n",
            "MISC: 144\n",
            "\n",
            "Most common entities:\n",
            "Finland: 93\n",
            "Finnish: 34\n",
            "Helsinki: 29\n",
            "Covid: 19\n",
            "Yle: 14\n",
            "Y: 13\n",
            "Afghanistan: 12\n",
            "Afghan: 11\n",
            "A: 10\n",
            "V: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kYZuWV9-UorQ"
      },
      "id": "kYZuWV9-UorQ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}